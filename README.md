# YouTube Transcription Pipeline

A production-grade API for YouTube video transcription and transcript management. Features automatic cookie management, Whisper fallback, REST API with authentication, rate limiting, Prometheus metrics, MCP integration, and **channel tracking**.

## Features

### Core Features
- **Simple 2-Step Pipeline**: Get transcript â†’ Save to MongoDB
- **Automatic Fallback**: YouTube API â†’ Whisper transcription
- **Auto Cookie Management**: Extracts cookies from Chrome automatically
- **Rate Limiting**: Configurable delays to prevent IP blocking (2-5s default)
- **Retry Logic**: Exponential backoff for rate-limited requests
- **YouTube API Cookie Support**: Passes browser cookies to API for less detectable requests
- **OpenVINO Whisper**: Optimized transcription with GPU/CPU support

### API Features
- **REST API**: FastAPI endpoints for async transcription jobs
- **OpenAPI Documentation**: Interactive docs at `/docs` and `/redoc`
- **API Key Authentication**: Optional authentication with tiered access
- **Rate Limiting**: Per-key rate limiting with Redis backend
- **Health Checks**: Comprehensive health endpoints for monitoring
- **Prometheus Metrics**: Detailed metrics for monitoring and alerting

### AI Integration
- **MCP Server**: Model Context Protocol support for AI assistants
- **Tools**: Transcribe, search, and manage transcripts via AI
- **Resources**: Direct access to transcripts and job status
- **Prompts**: Pre-defined workflows for common tasks

### Data Management
- **MongoDB Storage**: Full transcripts with timestamps
- **Redis Cache**: Job queue and caching (optional)
- **Channel Tracking**: Track YouTube channels and sync all videos with metadata
- **YAML Configuration**: Centralized config file for all settings

## Installation

```bash
# Clone repository
git clone <repository-url>
cd youtube-content-pipeline

# Install dependencies
uv sync
```

### Requirements

- Python 3.12+
- FFmpeg (for audio processing)
- MongoDB (optional, for data storage)
- Redis (optional, for caching and rate limiting)
- Chrome browser (for cookie extraction)
- Node.js or Deno (for YouTube JS challenges)

### Optional Dependencies

```bash
# With Redis support
uv sync --extra redis

# With all extras
uv sync --all-extras
```

## Quick Start

### Transcribe a YouTube Video

```bash
# Basic transcription
uv run python -m src.cli transcribe "https://youtube.com/watch?v=VIDEO_ID"

# With verbose output
uv run python -m src.cli transcribe "https://youtube.com/watch?v=VIDEO_ID" --verbose

# Save to file
uv run python -m src.cli transcribe "URL" --output transcript.json

# Skip database save
uv run python -m src.cli transcribe "URL" --no-db
```

### Track YouTube Channels

```bash
# Add channel to tracking
uv run python -m src.cli channel add @ChartChampions

# Add channels from video URLs (extracts channel info automatically)
uv run python -m src.cli channel add-from-videos \
  "https://youtu.be/S9s1rZKO_18" \
  "https://youtu.be/fpKtJLc5Ntg" \
  --sync --sync-mode recent

# Cookie management
uv run python -m src.cli cookie status      # Check cookie status
uv run python -m src.cli cookie extract      # Extract cookies from Chrome
uv run python -m src.cli cookie invalidate    # Force re-extraction

# Sync latest videos (RSS feed, ~15 videos, 2 seconds)
uv run python -m src.cli channel sync @ChartChampions

# Sync ALL videos with full metadata (slower, ~1.3s per video)
uv run python -m src.cli channel sync @ChartChampions --all --max-videos 500

# Smart incremental sync (only fetch metadata for NEW videos)
uv run python -m src.cli channel sync @ChartChampions --all --incremental

# List tracked channels
uv run python -m src.cli channel list

# List videos from channel
uv run python -m src.cli channel videos @ChartChampions --limit 20

# Transcribe pending videos (5 at a time, default)
uv run python -m src.cli channel transcribe-pending @ChartChampions

# Transcribe pending videos in custom batch size
uv run python -m src.cli channel transcribe-pending @ChartChampions --batch-size 20

# Transcribe ALL pending videos at once (may take hours)
uv run python -m src.cli channel transcribe-pending @ChartChampions --all

# Transcribe ALL pending videos in custom batch sizes (recommended)
uv run python -m src.cli channel transcribe-pending @ChartChampions --all --batch-size 20
```

### Transcribe All Videos from Channels

```bash
# Step 1: Add and sync channel
uv run python -m src.cli channel add @ChartChampions
uv run python -m src.cli channel sync @ChartChampions --all --max-videos 500

# Step 2: Transcribe all pending videos (in batches of 10)
uv run python -m src.cli channel transcribe-pending @ChartChampions --batch-size 10

# Step 3: Check progress
uv run python -m src.cli channel videos @ChartChampions --status completed --limit 10
uv run python -m src.cli channel videos @ChartChampions --status pending --limit 10

# Transcribe ALL channels at once
uv run python -m src.cli channel transcribe-pending --batch-size 10

# Transcribe from specific channel
uv run python -m src.cli channel transcribe-pending @ChartChampions --batch-size 10
```

### Full Workflow: Add Channel â†’ Sync â†’ Transcribe All

```bash
# Complete workflow for a new channel
uv run python -m src.cli channel add @ChartChampions          # Add channel
uv run python -m src.cli channel sync @ChartChampions --all   # Get all videos
uv run python -m src.cli channel transcribe-pending @ChartChampions --batch-size 10  # Transcribe

# For large channels (1000+ videos), transcribe in multiple batches:
# Run this command repeatedly until all videos are transcribed
uv run python -m src.cli channel transcribe-pending @ChartChampions --batch-size 10
```

### Batch Transcription

```bash
# Create a file with video sources (one per line)
echo "https://youtube.com/watch?v=VIDEO_ID1" > sources.txt
echo "https://youtube.com/watch?v=VIDEO_ID2" >> sources.txt

# Run batch transcription
uv run python -m src.cli batch sources.txt
```

### Start the API Server

```bash
# Basic server
uv run uvicorn src.api.main:app --reload

# With Prometheus metrics
uv run uvicorn src.api.main:app --reload --host 0.0.0.0

# Production (with workers)
uv run uvicorn src.api.main:app --workers 4 --host 0.0.0.0 --port 8000
```

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/videos/transcribe` | Submit video for transcription |
| `POST` | `/api/v1/videos/batch-transcribe` | Batch transcription (up to 100 videos) |
| `GET` | `/api/v1/videos/jobs/{job_id}` | Check job status |
| `GET` | `/api/v1/videos/jobs` | List transcription jobs |
| `GET` | `/api/v1/transcripts/{video_id}` | Get transcript |
| `GET` | `/api/v1/transcripts/` | List transcripts |
| `DELETE` | `/api/v1/transcripts/{video_id}` | Delete transcript |
| `GET` | `/api/v1/channels/` | List tracked channels |
| `GET` | `/api/v1/channels/{channel_id}` | Get channel details |
| `DELETE` | `/api/v1/channels/{channel_id}` | Remove channel from tracking |
| `POST` | `/api/v1/channels/{channel_id}/sync` | Trigger channel sync |
| `GET` | `/api/v1/channels/{channel_id}/videos` | Get channel videos |
| `GET` | `/api/v1/stats/` | Get system statistics |
| `GET` | `/health` | Basic health check |
| `GET` | `/health/ready` | Readiness probe |
| `GET` | `/health/detailed` | Detailed health status |
| `GET` | `/metrics` | Prometheus metrics |

### API Documentation

Interactive API documentation is available at:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI Spec**: http://localhost:8000/openapi.json

See [API_USAGE_GUIDE.md](API_USAGE_GUIDE.md) for detailed usage examples.

## Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# MongoDB
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=video_pipeline

# Redis (optional)
REDIS_URL=redis://localhost:6379
REDIS_ENABLED=true

# API Authentication (optional)
API_KEYS=key1,key2,key3
AUTH_REQUIRE_KEY=false

# OpenVINO Whisper
OPENVINO_WHISPER_MODEL=openai/whisper-base
OPENVINO_DEVICE=AUTO
OPENVINO_CACHE_DIR=~/.cache/whisper_openvino

# Prometheus
PROMETHEUS_ENABLED=true
PROMETHEUS_PATH=/metrics
```

See [CONFIGURATION_REFERENCE.md](CONFIGURATION_REFERENCE.md) for complete configuration options.

### YAML Configuration (Recommended)

Create a `config.yaml` file in the project root for runtime settings:

```yaml
# Rate Limiting - Prevents IP blocking
rate_limiting:
  enabled: true
  min_delay: 2.0        # Random delay between 2-5 seconds
  max_delay: 5.0
  retry_delay: 10.0     # Base delay for exponential backoff
  max_retries: 3

# YouTube API Settings
youtube_api:
  use_cookies: true     # Use browser cookies to avoid detection
  cookie_cache_hours: 24
  timeout: 30
  languages:
    - en
    - en-US

# Batch Processing
batch:
  default_size: 5       # Default videos per batch
  show_progress: true

# Whisper Settings
whisper:
  audio_format: mp3
  audio_bitrate: 128k
  chunk_length: 30

# Pipeline Settings
pipeline:
  work_dir: /tmp/transcription_pipeline
  cache_dir: /tmp/transcription_cache
  enable_cache: true
  save_to_db: true
```

### Environment Variables (.env)

Environment variables take precedence over `config.yaml`:

```bash
# MongoDB
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=video_pipeline

# OpenVINO Whisper
OPENVINO_WHISPER_MODEL=openai/whisper-base
OPENVINO_DEVICE=AUTO  # AUTO, GPU, or CPU
OPENVINO_CACHE_DIR=~/.cache/whisper_openvino
```

## MCP Integration

The pipeline includes an MCP (Model Context Protocol) server for AI assistant integration.

### Running the MCP Server

```bash
uv run python -m src.mcp.server
```

### Claude Desktop Configuration

Add to `claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "youtube-transcription": {
      "command": "uv",
      "args": ["run", "python", "-m", "src.mcp.server"],
      "cwd": "/home/muham/development/youtube-content-pipeline"
    }
  }
}
```

### Available Tools

- `transcribe_video` - Transcribe a YouTube video
- `get_transcript` - Retrieve a transcript by video ID
- `list_transcripts` - List all transcripts
- `get_job_status` - Check job status
- `add_channel` - Add channel to tracking
- `list_channels` - List all tracked channels
- `remove_channel` - Remove channel from tracking
- `sync_channel` - Sync channel videos
- `list_channel_videos` - List videos for a channel
- `transcribe_channel_pending` - Transcribe pending videos

See [MCP_INTEGRATION_GUIDE.md](MCP_INTEGRATION_GUIDE.md) for detailed setup.

---

## Monitoring

### Prometheus Metrics

Metrics are exposed at `/metrics`:

- API request rates and latency
- Transcription job metrics
- Database operation metrics
- Redis operation metrics

### Health Checks

| Endpoint | Description |
|----------|-------------|
| `/health` | Basic liveness probe |
| `/health/ready` | Readiness probe (checks dependencies) |
| `/health/detailed` | Comprehensive health status |

### Grafana Dashboard

Set up Prometheus and Grafana for monitoring:

```bash
# See Prometheus WSL setup guide
```

See [PROMETHEUS_WSL_SETUP.md](PROMETHEUS_WSL_SETUP.md) for complete monitoring setup.

---

## Architecture

### Pipeline Architecture

```
YouTube URL / Local Video
    |
Step 1: Get Transcript
    â”œâ”€â”€ YouTube Transcript API (fast)
    â””â”€â”€ Fallback: yt-dlp + OpenVINO Whisper (with cookies)
    |
Step 2: Save to MongoDB
    â””â”€â”€ Full transcript with timestamps
```

### API Architecture

```
Client Request
    |
Rate Limiter (Redis/Memory)
    |
API Key Authentication (optional)
    |
FastAPI Router
    |
â”œâ”€â”€ Videos Router â†’ Transcription Job
â”œâ”€â”€ Transcripts Router â†’ MongoDB
â””â”€â”€ Health Router â†’ Component Checks
    |
Prometheus Metrics (all requests)
```

### MCP Architecture

```
AI Assistant (Claude, etc.)
    |
MCP Protocol (STDIO/SSE)
    |
MCP Server (FastMCP)
    |
â”œâ”€â”€ Tools â†’ Transcription API
â”œâ”€â”€ Resources â†’ MongoDB
â””â”€â”€ Prompts â†’ Workflow Templates
```

## Channel Tracking Architecture

```
YouTube Channel (@Handle)
    |
Resolve Channel ID
    |
Fetch Videos
    â”œâ”€â”€ RSS Feed (fast, ~15 latest videos)
    â””â”€â”€ yt-dlp --simulate (complete metadata, all videos)
    |
Save to MongoDB
    â”œâ”€â”€ channels collection (channel metadata)
    â””â”€â”€ video_metadata collection (video info + transcript status)
    |
Transcribe Pending
    â””â”€â”€ Process videos with transcript_status="pending"
```

### Video Metadata Stored

For each video:
- `video_id` - Unique YouTube video ID
- `title` - Video title
- `description` - Full description
- `thumbnail_url` - Video thumbnail
- `duration_seconds` - Video duration
- `view_count` - View count
- `published_at` - Upload date
- `transcript_status` - pending/completed/failed
- `transcript_id` - Reference to transcript document

### Sync Strategies

| Method | Command | Speed | Use Case |
|--------|---------|-------|----------|
| **RSS (default)** | `channel sync @Handle` | âš¡ 2s | Daily checks |
| **Incremental** | `channel sync @Handle --all --incremental` | ğŸ§  Variable | Catch-up |
| **Full Sync** | `channel sync @Handle --all --max-videos 500` | ğŸŒ 1.3s/video | Complete refresh |

**Recommended Workflow:**
- **Daily**: `channel sync @Handle` (2 seconds)
- **Weekly**: `channel sync @Handle --all --incremental` (catch up on new videos)
- **Monthly**: `channel sync @Handle --all --max-videos 1000` (complete refresh)

See `CHANNEL_SYNC_GUIDE.md` for detailed documentation.

## Project Structure

```
src/
â”œâ”€â”€ __init__.py                 # Package exports
â”œâ”€â”€ cli.py                      # CLI interface
â”œâ”€â”€ database.py                 # MongoDB integration
â”œâ”€â”€ channel/                    # Channel tracking module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ resolver.py            # Handle â†’ Channel ID
â”‚   â”œâ”€â”€ feed_fetcher.py        # RSS + yt-dlp fetching
â”‚   â”œâ”€â”€ sync.py                # Sync logic
â”‚   â””â”€â”€ schemas.py             # Channel/Video schemas
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                # FastAPI app
â”‚   â”œâ”€â”€ app.py                 # App factory
â”‚   â”œâ”€â”€ dependencies.py        # FastAPI dependencies
â”‚   â”œâ”€â”€ security.py            # API key authentication
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ prometheus.py      # Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py    # Rate limiting
â”‚   â”‚   â”œâ”€â”€ error_handler.py   # Error handling
â”‚   â”‚   â””â”€â”€ logging.py         # Request logging
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ videos.py          # Transcription endpoints
â”‚   â”‚   â”œâ”€â”€ transcripts.py     # Transcript retrieval
â”‚   â”‚   â”œâ”€â”€ channels.py        # Channel management
â”‚   â”‚   â”œâ”€â”€ stats.py           # Statistics endpoint
â”‚   â”‚   â””â”€â”€ health.py          # Health checks
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ requests.py        # Request models
â”‚       â””â”€â”€ errors.py          # Error models
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â”œâ”€â”€ constants.py           # Application constants
â”‚   â”œâ”€â”€ exceptions.py          # Custom exceptions
â”‚   â”œâ”€â”€ schemas.py             # Pydantic models
â”‚   â””â”€â”€ logging_config.py      # Logging configuration
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ transcript.py          # Main pipeline
â”œâ”€â”€ transcription/
â”‚   â”œâ”€â”€ handler.py             # Transcription with fallback
â”‚   â””â”€â”€ whisper_openvino.py    # OpenVINO Whisper
â”œâ”€â”€ video/
â”‚   â””â”€â”€ cookie_manager.py      # Browser cookie management
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ manager.py             # Database manager
â”‚   â”œâ”€â”€ models.py              # Database models
â”‚   â””â”€â”€ redis.py               # Redis integration
â””â”€â”€ mcp/
    â”œâ”€â”€ server.py              # MCP server
    â”œâ”€â”€ config.py              # MCP configuration
    â”œâ”€â”€ tools/
    â”‚   â”œâ”€â”€ transcription.py   # Transcription tools
    â”‚   â”œâ”€â”€ transcripts.py     # Transcript tools
    â”‚   â””â”€â”€ channels.py        # Channel tools
    â”œâ”€â”€ resources/
    â”‚   â”œâ”€â”€ transcripts.py     # Transcript resources
    â”‚   â””â”€â”€ jobs.py            # Job resources
    â””â”€â”€ prompts/
        â”œâ”€â”€ transcribe.py      # Transcription prompts
        â””â”€â”€ channel_sync.py    # Channel sync prompts
```

## Programmatic API

```python
from src.pipeline import get_transcript, TranscriptPipeline

# Simple transcription
result = get_transcript("https://youtube.com/watch?v=VIDEO_ID")

# Access results
print(result.video_id)
print(result.segment_count)
print(result.duration_seconds)
print(result.transcript_source)  # "youtube_api" or "whisper"

# With custom settings
pipeline = TranscriptPipeline(work_dir="/custom/path")
result = pipeline.process("URL", save_to_db=False)
```

### Channel Tracking API

```python
from src.channel import sync_channel, get_pending_videos

# Sync channel
result = sync_channel("@ChartChampions", mode="all", max_videos=500)
print(f"Fetched {result.videos_fetched} videos")

# Get pending videos
pending = get_pending_videos(channel_id="UCHOP_YfwdMk5hpxbugzC1wA")
print(f"{len(pending)} videos pending transcription")
```

## Database Operations

```python
import asyncio
from src.database import get_db_manager

async def db_operations():
    db = get_db_manager()

    # Get transcript
    transcript = await db.get_transcript("video_id")

    # List transcripts
    transcripts = await db.list_transcripts(limit=10)

    # List channels
    channels = await db.list_channels()

    # Get pending videos
    pending = await db.get_pending_transcription_videos()

    await db.close()

asyncio.run(db_operations())
```

## Cookie Management

Cookies are automatically extracted from Chrome and used for:
- YouTube video downloads (yt-dlp)
- YouTube Transcript API requests (makes requests less detectable)

```bash
# Check cookie status
uv run python -m src.video.cookie_manager --status

# Force re-extraction
uv run python -m src.video.cookie_manager --invalidate
```

Cookies are cached for 24 hours by default (configurable in `config.yaml`).

## Running Tests

```bash
# Run all tests
uv run pytest tests/ -v

# Run specific test file
uv run pytest tests/test_pipeline.py -v
```

## Documentation

| Document | Description |
|----------|-------------|
| [README.md](README.md) | Overview and quick start |
| [API_USAGE_GUIDE.md](API_USAGE_GUIDE.md) | Complete API usage with examples |
| [MCP_INTEGRATION_GUIDE.md](MCP_INTEGRATION_GUIDE.md) | MCP server setup and usage |
| [PROMETHEUS_WSL_SETUP.md](PROMETHEUS_WSL_SETUP.md) | Prometheus and Grafana setup |
| [CONFIGURATION_REFERENCE.md](CONFIGURATION_REFERENCE.md) | All configuration options |
| [CHANNEL_SYNC_GUIDE.md](CHANNEL_SYNC_GUIDE.md) | Channel sync strategies |
| [AGENTS.md](AGENTS.md) | Development guidelines |
| [INTEL_ARC_GPU_GUIDE.md](INTEL_ARC_GPU_GUIDE.md) | Intel Arc GPU setup |

### Interactive Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI Spec**: http://localhost:8000/openapi.json

## Production Deployment

### Docker Deployment

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install dependencies
RUN pip install uv
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen

# Copy application
COPY src/ ./src/
COPY config.yaml ./

# Set environment variables
ENV PYTHONPATH=/app
ENV MONGODB_URL=mongodb://mongo:27017
ENV REDIS_URL=redis://redis:6379

# Run application
CMD ["uv", "run", "uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MONGODB_URL=mongodb://mongo:27017
      - REDIS_URL=redis://redis:6379
    depends_on:
      - mongo
      - redis

  mongo:
    image: mongo:7
    volumes:
      - mongo_data:/data/db

  redis:
    image: redis:7
    volumes:
      - redis_data:/data

  prometheus:
    image: prom/prometheus:v2.47.0
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:10.1.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  mongo_data:
  redis_data:
```

### Kubernetes (Basic)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: transcription-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: transcription-api
  template:
    metadata:
      labels:
        app: transcription-api
    spec:
      containers:
      - name: api
        image: transcription-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: MONGODB_URL
          valueFrom:
            secretKeyRef:
              name: mongo-secret
              key: url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: url
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8000
          initialDelaySeconds: 15
          periodSeconds: 20
```

### Security Considerations

1. **API Keys**: Use strong, unique API keys. Rotate regularly.
2. **HTTPS**: Always use HTTPS in production.
3. **Rate Limiting**: Enable rate limiting to prevent abuse.
4. **Database**: Use authentication and TLS for MongoDB/Redis.
5. **Secrets**: Store secrets in environment variables or secret manager.
6. **Monitoring**: Enable Prometheus metrics and set up alerts.

---

## License

MIT
